#. TRANSLATORS: def String.capitalize(string)
#: lib/string.ex:553 
msgid ""
"Converts the first character in the given string to\n"
"uppercase and the remainder to lowercase.\n"
"\n"
"This relies on the titlecase information provided\n"
"by the Unicode Standard. Note this function makes\n"
"no attempt to capitalize all words in the string\n"
"(usually known as titlecase).\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.capitalize(\"abcd\")\n"
"    \"Abcd\"\n"
"\n"
"    iex> String.capitalize(\"ﬁn\")\n"
"    \"Fin\"\n"
"\n"
"    iex> String.capitalize(\"olá\")\n"
"    \"Olá\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.chunk(string, trait)
#: lib/string.ex:1098 
msgid ""
"Splits the string into chunks of characters that share a common trait.\n"
"\n"
"The trait can be one of two options:\n"
"\n"
"  * `:valid`     - the string is split into chunks of valid and invalid character\n"
"    sequences\n"
"\n"
"  * `:printable` - the string is split into chunks of printable and\n"
"    non-printable character sequences\n"
"\n"
"Returns a list of binaries each of which contains only one kind of\n"
"characters.\n"
"\n"
"If the given string is empty, an empty list is returned.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.chunk(<<?a, ?b, ?c, 0>>, :valid)\n"
"    [\"abc\\0\"]\n"
"\n"
"    iex> String.chunk(<<?a, ?b, ?c, 0, 0x0ffff::utf8>>, :valid)\n"
"    [\"abc\\0\", <<0x0ffff::utf8>>]\n"
"\n"
"    iex> String.chunk(<<?a, ?b, ?c, 0, 0x0ffff::utf8>>, :printable)\n"
"    [\"abc\", <<0, 0x0ffff::utf8>>]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_trailing(string, match, replacement)
#: lib/string.ex:645 
msgid ""
"Replaces all trailing occurences of `match` by `replacement` in `string`.\n"
"\n"
"Returns the string untouched if there are no occurrences.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_trailing(\"hello world\", \" world\", \"\")\n"
"    \"hello\"\n"
"    iex> String.replace_trailing(\"hello world world\", \" world\", \"\")\n"
"    \"hello\"\n"
"\n"
"    iex> String.replace_trailing(\"hello world\", \" world\", \" mundo\")\n"
"    \"hello mundo\"\n"
"    iex> String.replace_trailing(\"hello world world\", \" world\", \" mundo\")\n"
"    \"hello mundo mundo\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.normalize(string, form)
#: lib/string.ex:489 
msgid ""
"Converts all characters in `string` to Unicode normalization\n"
"form identified by `form`.\n"
"\n"
"## Forms\n"
"\n"
"The supported forms are:\n"
"\n"
"  * `:nfd` - Normalization Form Canonical Decomposition.\n"
"    Characters are decomposed by canonical equivalence, and\n"
"    multiple combining characters are arranged in a specific\n"
"    order.\n"
"\n"
"  * `:nfc` - Normalization Form Canonical Composition.\n"
"    Characters are decomposed and then recomposed by canonical equivalence.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.normalize(\"yêṩ\", :nfd)\n"
"    \"yêṩ\"\n"
"\n"
"    iex> String.normalize(\"leña\", :nfc)\n"
"    \"leña\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_float(string)
#: lib/string.ex:1698 
msgid ""
"Returns a float whose text representation is `string`.\n"
"\n"
"`string` must be the string representation of a float.\n"
"If a string representation of an integer wants to be used,\n"
"then `Float.parse/1` should be used instead,\n"
"otherwise an argument error will be raised.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_float(\"2.2017764e+0\")\n"
"    2.2017764\n"
"\n"
"    iex> String.to_float(\"3.0\")\n"
"    3.0\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_suffix(string, match, replacement)
#: lib/string.ex:718 
msgid ""
"Replaces suffix in `string` by `replacement` if it matches `match`.\n"
"\n"
"Returns the string untouched if there is no match.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_suffix(\"hello\", \" world\", \"\")\n"
"    \"hello\"\n"
"    iex> String.replace_suffix(\"hello world\", \" world\", \"\")\n"
"    \"hello\"\n"
"    iex> String.replace_suffix(\"hello world world\", \" world\", \"\")\n"
"    \"hello world\"\n"
"\n"
"    iex> String.replace_suffix(\"hello\", \" world\", \" mundo\")\n"
"    \"hello\"\n"
"    iex> String.replace_suffix(\"hello world\", \" world\", \" mundo\")\n"
"    \"hello mundo\"\n"
"    iex> String.replace_suffix(\"hello world world\", \" world\", \" mundo\")\n"
"    \"hello world mundo\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace(subject, pattern, replacement, options \\ [])
#: lib/string.ex:876 
msgid ""
"Returns a new string created by replacing occurences of `pattern` in\n"
"`subject` with `replacement`.\n"
"\n"
"By default, it replaces all occurences, unless the `global` option is\n"
"set to `false`, where it will only replace the first one\n"
"\n"
"The `pattern` may be a string or a regular expression.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"-\")\n"
"    \"a-b-c\"\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"-\", global: false)\n"
"    \"a-b,c\"\n"
"\n"
"When the pattern is a regular expression, one can give `\\N` or\n"
"`\\g{N}` in the `replacement` string to access a specific capture in the\n"
"regular expression:\n"
"\n"
"    iex> String.replace(\"a,b,c\", ~r/,(.)/, \",\\\\1\\\\g{1}\")\n"
"    \"a,bb,cc\"\n"
"\n"
"Notice we had to escape the escape character `\\`. By giving `\\0`,\n"
"one can inject the whole matched pattern in the replacement string.\n"
"\n"
"When the pattern is a string, a developer can use the replaced part inside\n"
"the `replacement` by using the `:insert_replace` option and specifying the\n"
"position(s) inside the `replacement` where the string pattern will be\n"
"inserted:\n"
"\n"
"    iex> String.replace(\"a,b,c\", \"b\", \"[]\", insert_replaced: 1)\n"
"    \"a,[b],c\"\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"[]\", insert_replaced: 2)\n"
"    \"a[],b[],c\"\n"
"\n"
"    iex> String.replace(\"a,b,c\", \",\", \"[]\", insert_replaced: [1, 1])\n"
"    \"a[,,]b[,,]c\"\n"
"\n"
"If any position given in the `:insert_replace` option is larger than the\n"
"replacement string, or is negative, an `ArgumentError` is raised.\n"
msgstr ""
#. TRANSLATORS: def String.at(string, position)
#: lib/string.ex:1279 
msgid ""
"Returns the grapheme at the `position` of the given utf8 `string`.\n"
"If `position` is greater than `string` length, then it returns `nil`.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.at(\"elixir\", 0)\n"
"    \"e\"\n"
"\n"
"    iex> String.at(\"elixir\", 1)\n"
"    \"l\"\n"
"\n"
"    iex> String.at(\"elixir\", 10)\n"
"    nil\n"
"\n"
"    iex> String.at(\"elixir\", -1)\n"
"    \"r\"\n"
"\n"
"    iex> String.at(\"elixir\", -10)\n"
"    nil\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_leading(string, match, replacement)
#: lib/string.ex:607 
msgid ""
"Replaces all leading occurences of `match` by `replacement` of `match` in `string`.\n"
"\n"
"Returns the string untouched if there are no occurrences.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_leading(\"hello world\", \"hello \", \"\")\n"
"    \"world\"\n"
"    iex> String.replace_leading(\"hello hello world\", \"hello \", \"\")\n"
"    \"world\"\n"
"\n"
"    iex> String.replace_leading(\"hello world\", \"hello \", \"ola \")\n"
"    \"ola world\"\n"
"    iex> String.replace_leading(\"hello hello world\", \"hello \", \"ola \")\n"
"    \"ola ola world\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.reverse(string)
#: lib/string.ex:944 
msgid ""
"Reverses the graphemes in given string.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.reverse(\"abcd\")\n"
"    \"dcba\"\n"
"\n"
"    iex> String.reverse(\"hello world\")\n"
"    \"dlrow olleh\"\n"
"\n"
"    iex> String.reverse(\"hello ∂og\")\n"
"    \"go∂ olleh\"\n"
"\n"
"Keep in mind reversing the same string twice does\n"
"not necessarily yield the original string:\n"
"\n"
"    iex> \"̀e\"\n"
"    \"̀e\"\n"
"    iex> String.reverse(\"̀e\")\n"
"    \"è\"\n"
"    iex> String.reverse String.reverse(\"̀e\")\n"
"    \"è\"\n"
"\n"
"In the first example the accent is before the vowel, so\n"
"it is considered two graphemes. However, when you reverse\n"
"it once, you have the vowel followed by the accent, which\n"
"becomes one grapheme. Reversing it again will keep it as\n"
"one single grapheme.\n"
msgstr ""
#. TRANSLATORS: def String.strip(string)
#: lib/string.ex:785 
msgid ""
"Returns a string where all leading and trailing Unicode whitespaces\n"
"have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.strip(\"   abc  \")\n"
"    \"abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.strip(string, char)
#: lib/string.ex:801 
msgid ""
"Returns a string where all leading and trailing `char`s have been\n"
"removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.strip(\"a  abc  a\", ?a)\n"
"    \"  abc  \"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.ends_with?(string, suffixes)
#: lib/string.ex:1509 
msgid ""
"Returns `true` if `string` ends with any of the suffixes given.\n"
"\n"
"`suffixes` can be either a single suffix or a list of suffixes.\n"
"\n"
"Raises argument error if an empty string is given.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.ends_with? \"language\", \"age\"\n"
"    true\n"
"\n"
"    iex> String.ends_with? \"language\", [\"youth\", \"age\"]\n"
"    true\n"
"\n"
"    iex> String.ends_with? \"language\", [\"youth\", \"elixir\"]\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_char_list(string)
#: lib/string.ex:1595 
msgid ""
"Converts a string into a char list.\n"
"\n"
"Specifically, this functions takes a UTF-8 encoded binary and returns a list of its integer\n"
"codepoints. It is similar to `codepoints/1` except that the latter returns a list of codepoints as\n"
"strings.\n"
"\n"
"In case you need to work with bytes, take a look at the\n"
"[`:binary` module](http://www.erlang.org/doc/man/binary.html).\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_char_list(\"æß\")\n"
"    'æß'\n"
msgstr ""
#. TRANSLATORS: def String.next_grapheme_size(string)
#: lib/string.ex:1203 
msgid ""
"Returns the size of the next grapheme.\n"
"\n"
"The result is a tuple with the next grapheme size and\n"
"the remainder of the string or `nil` in case the string\n"
"reached its end.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.next_grapheme_size(\"olá\")\n"
"    {1, \"lá\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.contains?(string, contents)
#: lib/string.ex:1561 
msgid ""
"Checks if `string` contains any of the given `contents`.\n"
"\n"
"`contents` can be either a single string or a list of strings.\n"
"\n"
"Raises argument error if an empty string is given.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.contains? \"elixir of life\", \"of\"\n"
"    true\n"
"\n"
"    iex> String.contains? \"elixir of life\", [\"life\", \"death\"]\n"
"    true\n"
"\n"
"    iex> String.contains? \"elixir of life\", [\"death\", \"mercury\"]\n"
"    false\n"
"\n"
"The argument can also be a precompiled pattern:\n"
"\n"
"    iex> pattern = :binary.compile_pattern([\"life\", \"death\"])\n"
"    iex> String.contains? \"elixir of life\", pattern\n"
"    true\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.slice(string, range)
#: lib/string.ex:1382 
msgid ""
"Returns a substring from the offset given by the start of the\n"
"range to the offset given by the end of the range.\n"
"\n"
"If the start of the range is not a valid offset for the given\n"
"string or if the range is in reverse order, returns `\"\"`.\n"
"\n"
"If the start or end of the range is negative, the whole string\n"
"is traversed first in order to convert the negative indices into\n"
"positive ones.\n"
"\n"
"Remember this function works with Unicode graphemes and considers\n"
"the slices to represent grapheme offsets. If you want to split\n"
"on raw bytes, check `Kernel.binary_part/3` instead.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.slice(\"elixir\", 1..3)\n"
"    \"lix\"\n"
"\n"
"    iex> String.slice(\"elixir\", 1..10)\n"
"    \"lixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", 10..3)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"elixir\", -4..-1)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", 2..-1)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", -4..6)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", -1..-4)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"elixir\", -10..-7)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"a\", 0..1500)\n"
"    \"a\"\n"
"\n"
"    iex> String.slice(\"a\", 1..1500)\n"
"    \"\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.lstrip(binary)
#: lib/string.ex:753 
msgid ""
"Returns a string where all leading Unicode whitespaces\n"
"have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.lstrip(\"   abc  \")\n"
"    \"abc  \"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.valid?(string)
#: lib/string.ex:1053 
msgid ""
"Checks whether `string` contains only valid characters.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.valid?(\"a\")\n"
"    true\n"
"\n"
"    iex> String.valid?(\"ø\")\n"
"    true\n"
"\n"
"    iex> String.valid?(<<0xffff :: 16>>)\n"
"    false\n"
"\n"
"    iex> String.valid?(\"asd\" <> <<0xffff :: 16>>)\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.upcase(binary)
#: lib/string.ex:517 
msgid ""
"Converts all characters in the given string to uppercase.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.upcase(\"abcd\")\n"
"    \"ABCD\"\n"
"\n"
"    iex> String.upcase(\"ab 123 xpto\")\n"
"    \"AB 123 XPTO\"\n"
"\n"
"    iex> String.upcase(\"olá\")\n"
"    \"OLÁ\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.lstrip(string, char)
#: lib/string.ex:765 
msgid ""
"Returns a string where all leading `char`s have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.lstrip(\"_  abc  _\", ?_)\n"
"    \"  abc  _\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.equivalent?(string1, string2)
#: lib/string.ex:457 
msgid ""
"Returns `true` if `string1` is canonically equivalent to 'string2'.\n"
"\n"
"It performs Normalization Form Canonical Decomposition (NFD) on the\n"
"strings before comparing them. This function is equivalent to:\n"
"\n"
"    String.normalize(string1, :nfd) == String.normalize(string2, :nfd)\n"
"\n"
"Therefore, if you plan to compare multiple strings, multiple times\n"
"in a row, you may normalize them upfront and compare them directly\n"
"to avoid multiple normalization passes.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.equivalent?(\"abc\", \"abc\")\n"
"    true\n"
"\n"
"    iex> String.equivalent?(\"man\\u0303ana\", \"mañana\")\n"
"    true\n"
"\n"
"    iex> String.equivalent?(\"abc\", \"ABC\")\n"
"    false\n"
"\n"
"    iex> String.equivalent?(\"nø\", \"nó\")\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.split_at(string, position)
#: lib/string.ex:407 
msgid ""
"Splits a string into two at the specified offset. When the offset given is\n"
"negative, location is counted from the end of the string.\n"
"\n"
"The offset is capped to the length of the string. Returns a tuple with\n"
"two elements.\n"
"\n"
"Note: keep in mind this function splits on graphemes and for such it\n"
"has to linearly traverse the string. If you want to split a string or\n"
"a binary based on the number of bytes, use `Kernel.binary_part/3`\n"
"instead.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.split_at \"sweetelixir\", 5\n"
"    {\"sweet\", \"elixir\"}\n"
"\n"
"    iex> String.split_at \"sweetelixir\", -6\n"
"    {\"sweet\", \"elixir\"}\n"
"\n"
"    iex> String.split_at \"abc\", 0\n"
"    {\"\", \"abc\"}\n"
"\n"
"    iex> String.split_at \"abc\", 1000\n"
"    {\"abc\", \"\"}\n"
"\n"
"    iex> String.split_at \"abc\", -1000\n"
"    {\"\", \"abc\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.rstrip(binary)
#: lib/string.ex:580 
msgid ""
"Returns a string where all trailing Unicode whitespaces\n"
"has been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.rstrip(\"   abc  \")\n"
"    \"   abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_atom(string)
#: lib/string.ex:1624 
msgid ""
"Converts a string to an atom.\n"
"\n"
"Currently Elixir does not support the conversion of strings\n"
"that contain Unicode codepoints greater than 0xFF.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_atom(\"my_atom\")\n"
"    :my_atom\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.graphemes(string)
#: lib/string.ex:1156 
msgid ""
"Returns Unicode graphemes in the string as per Extended Grapheme\n"
"Cluster algorithm.\n"
"\n"
"The algorithm is outlined in the [Unicode Standard Annex #29,\n"
"Unicode Text Segmentation](http://www.unicode.org/reports/tr29/).\n"
"\n"
"For details about codepoints and graphemes, see the `String` module documentation.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.graphemes(\"Ńaïve\")\n"
"    [\"Ń\", \"a\", \"ï\", \"v\", \"e\"]\n"
"\n"
"    iex> String.graphemes(\"é\")\n"
"    [\"é\"]\n"
"\n"
"    iex> String.graphemes(\"é\")\n"
"    [\"é\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.ljust(subject, len, pad \\ 32)
#: lib/string.ex:838 
msgid ""
"Returns a new string of length `len` with `subject` left justified and padded\n"
"with `pad`. If `pad` is not present, it defaults to whitespace. When\n"
"`len` is less than the length of `subject`, `subject` is returned.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.ljust(\"abc\", 5)\n"
"    \"abc  \"\n"
"\n"
"    iex> String.ljust(\"abc\", 5, ?-)\n"
"    \"abc--\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.duplicate(subject, n)
#: lib/string.ex:985 
msgid ""
"Returns a string `subject` duplicated `n` times.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.duplicate(\"abc\", 0)\n"
"    \"\"\n"
"\n"
"    iex> String.duplicate(\"abc\", 1)\n"
"    \"abc\"\n"
"\n"
"    iex> String.duplicate(\"abc\", 2)\n"
"    \"abcabc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.length(string)
#: lib/string.ex:1264 
msgid ""
"Returns the number of Unicode graphemes in a utf8 string.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.length(\"elixir\")\n"
"    6\n"
"\n"
"    iex> String.length(\"եոգլի\")\n"
"    5\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.replace_prefix(string, match, replacement)
#: lib/string.ex:683 
msgid ""
"Replaces prefix in `string` by `replacement` if it matches `match`.\n"
"\n"
"Returns the string untouched if there is no match.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.replace_prefix(\"world\", \"hello \", \"\")\n"
"    \"world\"\n"
"    iex> String.replace_prefix(\"hello world\", \"hello \", \"\")\n"
"    \"world\"\n"
"    iex> String.replace_prefix(\"hello hello world\", \"hello \", \"\")\n"
"    \"hello world\"\n"
"\n"
"    iex> String.replace_prefix(\"world\", \"hello \", \"ola \")\n"
"    \"world\"\n"
"    iex> String.replace_prefix(\"hello world\", \"hello \", \"ola \")\n"
"    \"ola world\"\n"
"    iex> String.replace_prefix(\"hello hello world\", \"hello \", \"ola \")\n"
"    \"ola hello world\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.last(string)
#: lib/string.ex:1240 
msgid ""
"Returns the last grapheme from a utf8 string,\n"
"`nil` if the string is empty.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.last(\"elixir\")\n"
"    \"r\"\n"
"\n"
"    iex> String.last(\"եոգլի\")\n"
"    \"ի\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.slice(string, start, len)
#: lib/string.ex:1322 
msgid ""
"Returns a substring starting at the offset `start`, and of\n"
"length `len`.\n"
"\n"
"If the offset is greater than string length, then it returns `\"\"`.\n"
"\n"
"Remember this function works with Unicode graphemes and considers\n"
"the slices to represent grapheme offsets. If you want to split\n"
"on raw bytes, check `Kernel.binary_part/3` instead.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.slice(\"elixir\", 1, 3)\n"
"    \"lix\"\n"
"\n"
"    iex> String.slice(\"elixir\", 1, 10)\n"
"    \"lixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", 10, 3)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"elixir\", -4, 4)\n"
"    \"ixir\"\n"
"\n"
"    iex> String.slice(\"elixir\", -10, 3)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"a\", 0, 1500)\n"
"    \"a\"\n"
"\n"
"    iex> String.slice(\"a\", 1, 1500)\n"
"    \"\"\n"
"\n"
"    iex> String.slice(\"a\", 2, 1500)\n"
"    \"\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.next_codepoint(string)
#: lib/string.ex:1031 
msgid ""
"Returns the next codepoint in a string.\n"
"\n"
"The result is a tuple with the codepoint and the\n"
"remainder of the string or `nil` in case\n"
"the string reached its end.\n"
"\n"
"As with other functions in the String module, this\n"
"function does not check for the validity of the codepoint.\n"
"That said, if an invalid codepoint is found, it will\n"
"be returned by this function.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.next_codepoint(\"olá\")\n"
"    {\"o\", \"lá\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.downcase(binary)
#: lib/string.ex:535 
msgid ""
"Converts all characters in the given string to lowercase.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.downcase(\"ABCD\")\n"
"    \"abcd\"\n"
"\n"
"    iex> String.downcase(\"AB 123 XPTO\")\n"
"    \"ab 123 xpto\"\n"
"\n"
"    iex> String.downcase(\"OLÁ\")\n"
"    \"olá\"\n"
"\n"
msgstr ""
#. TRANSLATORS: Elixir.String Summary
#: lib/string.ex:4 
msgid ""
"A String in Elixir is a UTF-8 encoded binary.\n"
"\n"
"## Codepoints and graphemes\n"
"\n"
"The functions in this module act according to the Unicode\n"
"Standard, version 6.3.0.\n"
"\n"
"As per the standard, a codepoint is a single Unicode Character,\n"
"which may be represented by one or more bytes.\n"
"\n"
"For example, the codepoint \"é\" is two bytes:\n"
"\n"
"    iex> byte_size(\"é\")\n"
"    2\n"
"\n"
"However, this module returns the proper length:\n"
"\n"
"    iex> String.length(\"é\")\n"
"    1\n"
"\n"
"Furthermore, this module also presents the concept of\n"
"graphemes. A single grapheme can consist of multiple codepoints\n"
"that may be perceived as a single character by readers. For example,\n"
"the \"é\" grapheme can be represented either as a single \"e with acute\"\n"
"codepoint (like above), or as the letter \"e\" followed by a\n"
"\"combining acute accent\" (two codepoints):\n"
"\n"
"    iex> string = \"\\u0065\\u0301\"\n"
"    iex> byte_size(string)\n"
"    3\n"
"    iex> String.length(string)\n"
"    1\n"
"    iex> String.codepoints(string)\n"
"    [\"e\", \"́\"]\n"
"    iex> String.graphemes(string)\n"
"    [\"é\"]\n"
"\n"
"Although the example above is made of two characters, it is\n"
"perceived by users as one.\n"
"\n"
"Graphemes can also be two characters that are interpreted\n"
"as one by some languages. For example, some languages may\n"
"consider \"ch\" as a grapheme. However, since this information\n"
"depends on the locale, it is not taken into account by this\n"
"module.\n"
"\n"
"In general, the functions in this module rely on the Unicode\n"
"Standard, but do not contain any of the locale specific behaviour.\n"
"\n"
"More information about graphemes can be found in the [Unicode\n"
"Standard Annex #29](http://www.unicode.org/reports/tr29/).\n"
"The current Elixir version implements Extended Grapheme Cluster\n"
"algorithm.\n"
"\n"
"## String and binary operations\n"
"\n"
"To act according to the Unicode Standard, many functions\n"
"in this module run in linear time, as they need to traverse\n"
"the whole string considering the proper Unicode codepoints.\n"
"\n"
"For example, `String.length/1` will take longer as\n"
"the input grows. On the other hand, `Kernel.byte_size/1` always runs\n"
"in constant time (i.e. regardless of the input size).\n"
"\n"
"This means often there are performance costs in using the\n"
"functions in this module, compared to the more low-level\n"
"operations that work directly with binaries:\n"
"\n"
"  * `Kernel.binary_part/3` - retrieves part of the binary\n"
"  * `Kernel.bit_size/1` and `Kernel.byte_size/1` - size related functions\n"
"  * `Kernel.is_bitstring/1` and `Kernel.is_binary/1` - type checking function\n"
"  * Plus a number of functions for working with binaries (bytes)\n"
"    in the [`:binary` module](http://www.erlang.org/doc/man/binary.html)\n"
"\n"
"There are many situations where using the `String` module can\n"
"be avoided in favor of binary functions or pattern matching.\n"
"For example, imagine you have a string `prefix` and you want to\n"
"remove this prefix from another string named `full`.\n"
"\n"
"One may be tempted to write:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = String.length(prefix)\n"
"    ...>   String.slice(full, base, String.length(full) - base)\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"Although the function above works, it performs poorly. To\n"
"calculate the length of the string, we need to traverse it\n"
"fully, so we traverse both `prefix` and `full` strings, then\n"
"slice the `full` one, traversing it again.\n"
"\n"
"A first attempt at improving it could be with ranges:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = String.length(prefix)\n"
"    ...>   String.slice(full, base..-1)\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"While this is much better (we don't traverse `full` twice),\n"
"it could still be improved. In this case, since we want to\n"
"extract a substring from a string, we can use `byte_size/1`\n"
"and `binary_part/3` as there is no chance we will slice in\n"
"the middle of a codepoint made of more than one byte:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = byte_size(prefix)\n"
"    ...>   binary_part(full, base, byte_size(full) - base)\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"Or simply use pattern matching:\n"
"\n"
"    iex> take_prefix = fn full, prefix ->\n"
"    ...>   base = byte_size(prefix)\n"
"    ...>   <<_::binary-size(base), rest::binary>> = full\n"
"    ...>   rest\n"
"    ...> end\n"
"    iex> take_prefix.(\"Mr. John\", \"Mr. \")\n"
"    \"John\"\n"
"\n"
"On the other hand, if you want to dynamically slice a string\n"
"based on an integer value, then using `String.slice/3` is the\n"
"best option as it guarantees we won't incorrectly split a valid\n"
"codepoint into multiple bytes.\n"
"\n"
"## Integer codepoints\n"
"\n"
"Although codepoints could be represented as integers, this\n"
"module represents all codepoints as strings. For example:\n"
"\n"
"    iex> String.codepoints(\"olá\")\n"
"    [\"o\", \"l\", \"á\"]\n"
"\n"
"There are a couple of ways to retrieve a character integer\n"
"codepoint. One may use the `?` construct:\n"
"\n"
"    iex> ?o\n"
"    111\n"
"\n"
"    iex> ?á\n"
"    225\n"
"\n"
"Or also via pattern matching:\n"
"\n"
"    iex> <<eacute::utf8>> = \"á\"\n"
"    iex> eacute\n"
"    225\n"
"\n"
"As we have seen above, codepoints can be inserted into\n"
"a string by their hexadecimal code:\n"
"\n"
"    \"ol\\u0061\\u0301\" #=>\n"
"    \"olá\"\n"
"\n"
"## Self-synchronization\n"
"\n"
"The UTF-8 encoding is self-synchronizing. This means that\n"
"if malformed data (i.e., data that is not possible according\n"
"to the definition of the encoding) is encountered, only one\n"
"codepoint needs to be rejected.\n"
"\n"
"This module relies on this behaviour to ignore such invalid\n"
"characters. For example, `length/1` will return\n"
"a correct result even if an invalid codepoint is fed into it.\n"
"\n"
"In other words, this module expects invalid data to be detected\n"
"when retrieving data from the external source. For example, a\n"
"driver that reads strings from a database will be\n"
"responsible to check the validity of the encoding.\n"
"\n"
"## Patterns\n"
"\n"
"Many functions in this module work with patterns. For example,\n"
"String.split/2 can split a string into multiple patterns given\n"
"a pattern. This pattern can be a string, a list of strings or\n"
"a compiled pattern:\n"
"\n"
"    iex> String.split(\"foo bar\", \" \")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\"foo bar!\", [\" \", \"!\"])\n"
"    [\"foo\", \"bar\", \"\"]\n"
"\n"
"    iex> pattern = :binary.compile_pattern([\" \", \"!\"])\n"
"    iex> String.split(\"foo bar!\", pattern)\n"
"    [\"foo\", \"bar\", \"\"]\n"
"\n"
"The compiled pattern is useful when the same match will\n"
"be done over and over again. Note though the compiled\n"
"pattern cannot be stored in a module attribute as the pattern\n"
"is generated at runtime and does not survive compile term.\n"
msgstr ""
#. TRANSLATORS: def String.first(string)
#: lib/string.ex:1219 
msgid ""
"Returns the first grapheme from a utf8 string,\n"
"`nil` if the string is empty.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.first(\"elixir\")\n"
"    \"e\"\n"
"\n"
"    iex> String.first(\"եոգլի\")\n"
"    \"ե\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.next_grapheme(binary)
#: lib/string.ex:1182 
msgid ""
"Returns the next grapheme in a string.\n"
"\n"
"The result is a tuple with the grapheme and the\n"
"remainder of the string or `nil` in case\n"
"the String reached its end.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.next_grapheme(\"olá\")\n"
"    {\"o\", \"lá\"}\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.printable?(string)
#: lib/string.ex:208 
msgid ""
"Checks if a string contains only printable characters.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.printable?(\"abc\")\n"
"    true\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.jaro_distance(string1, string2)
#: lib/string.ex:1722 
msgid ""
"Returns a float value between 0 (equates to no similarity) and 1 (is an exact match)\n"
"representing [Jaro](https://en.wikipedia.org/wiki/Jaro–Winkler_distance)\n"
"distance between `string1` and `string2`.\n"
"\n"
"The Jaro distance metric is designed and best suited for short strings such as person names.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.jaro_distance(\"dwayne\", \"duane\")\n"
"    0.8222222222222223\n"
"    iex> String.jaro_distance(\"even\", \"odd\")\n"
"    0.0\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.split(string, pattern, options \\ [])
#: lib/string.ex:265 
msgid ""
"Divides a string into substrings based on a pattern.\n"
"\n"
"Returns a list of these substrings. The pattern can\n"
"be a string, a list of strings or a regular expression.\n"
"\n"
"The string is split into as many parts as possible by\n"
"default, but can be controlled via the `parts: num` option.\n"
"If you pass `parts: :infinity`, it will return all possible parts\n"
"(being this one the default behaviour).\n"
"\n"
"Empty strings are only removed from the result if the\n"
"`trim` option is set to `true` (default is `false`).\n"
"\n"
"## Examples\n"
"\n"
"Splitting with a string pattern:\n"
"\n"
"    iex> String.split(\"a,b,c\", \",\")\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"a,b,c\", \",\", parts: 2)\n"
"    [\"a\", \"b,c\"]\n"
"\n"
"    iex> String.split(\" a b c \", \" \", trim: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"A list of patterns:\n"
"\n"
"    iex> String.split(\"1,2 3,4\", [\" \", \",\"])\n"
"    [\"1\", \"2\", \"3\", \"4\"]\n"
"\n"
"A regular expression:\n"
"\n"
"    iex> String.split(\"a,b,c\", ~r{,})\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"a,b,c\", ~r{,}, parts: 2)\n"
"    [\"a\", \"b,c\"]\n"
"\n"
"    iex> String.split(\" a b c \", ~r{\\s}, trim: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"Splitting on empty patterns returns graphemes:\n"
"\n"
"    iex> String.split(\"abc\", ~r{})\n"
"    [\"a\", \"b\", \"c\", \"\"]\n"
"\n"
"    iex> String.split(\"abc\", \"\")\n"
"    [\"a\", \"b\", \"c\", \"\"]\n"
"\n"
"    iex> String.split(\"abc\", \"\", trim: true)\n"
"    [\"a\", \"b\", \"c\"]\n"
"\n"
"    iex> String.split(\"abc\", \"\", parts: 2)\n"
"    [\"a\", \"bc\"]\n"
"\n"
"A precompiled pattern can also be given:\n"
"\n"
"    iex> pattern = :binary.compile_pattern([\" \", \",\"])\n"
"    iex> String.split(\"1,2 3,4\", pattern)\n"
"    [\"1\", \"2\", \"3\", \"4\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.rjust(subject, len, pad \\ 32)
#: lib/string.ex:816 
msgid ""
"Returns a new string of length `len` with `subject` right justified and\n"
"padded with `pad`. If `pad` is not present, it defaults to\n"
"whitespace. When `len` is less than the length of `subject`, `subject` is\n"
"returned.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.rjust(\"abc\", 5)\n"
"    \"  abc\"\n"
"\n"
"    iex> String.rjust(\"abc\", 5, ?-)\n"
"    \"--abc\"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_existing_atom(string)
#: lib/string.ex:1643 
msgid ""
"Converts a string to an existing atom.\n"
"\n"
"Currently Elixir does not support the conversion of strings\n"
"that contain Unicode codepoints greater than 0xFF.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> _ = :my_atom\n"
"    iex> String.to_existing_atom(\"my_atom\")\n"
"    :my_atom\n"
"\n"
"    iex> String.to_existing_atom(\"this_atom_will_never_exist\")\n"
"    ** (ArgumentError) argument error\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_integer(string, base)
#: lib/string.ex:1682 
msgid ""
"Returns an integer whose text representation is `string` in base `base`.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_integer(\"3FF\", 16)\n"
"    1023\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.rstrip(string, char)
#: lib/string.ex:593 
msgid ""
"Returns a string where all trailing `char`s have been removed.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.rstrip(\"   abc _\", ?_)\n"
"    \"   abc \"\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.splitter(string, pattern, options \\ [])
#: lib/string.ex:361 
msgid ""
"Returns an enumerable that splits a string on demand.\n"
"\n"
"This is in contrast to `split/3` which splits all\n"
"the string upfront.\n"
"\n"
"Note splitter does not support regular expressions\n"
"(as it is often more efficient to have the regular\n"
"expressions traverse the string at once than in\n"
"multiple passes).\n"
"\n"
"## Options\n"
"\n"
"  * :trim - when `true`, does not emit empty patterns\n"
msgstr ""
#. TRANSLATORS: def String.starts_with?(string, prefix)
#: lib/string.ex:1481 
msgid ""
"Returns `true` if `string` starts with any of the prefixes given.\n"
"\n"
"`prefixes` can be either a single prefix or a list of prefixes.\n"
"\n"
"Raises argument error if an empty string is given.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.starts_with? \"elixir\", \"eli\"\n"
"    true\n"
"\n"
"    iex> String.starts_with? \"elixir\", [\"erlang\", \"elixir\"]\n"
"    true\n"
"\n"
"    iex> String.starts_with? \"elixir\", [\"erlang\", \"ruby\"]\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.codepoints(string)
#: lib/string.ex:1005 
msgid ""
"Returns all codepoints in the string.\n"
"\n"
"For details about codepoints and graphemes, see the `String` module documentation.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.codepoints(\"olá\")\n"
"    [\"o\", \"l\", \"á\"]\n"
"\n"
"    iex> String.codepoints(\"оптими зации\")\n"
"    [\"о\", \"п\", \"т\", \"и\", \"м\", \"и\", \" \", \"з\", \"а\", \"ц\", \"и\", \"и\"]\n"
"\n"
"    iex> String.codepoints(\"ἅἪῼ\")\n"
"    [\"ἅ\", \"Ἢ\", \"ῼ\"]\n"
"\n"
"    iex> String.codepoints(\"é\")\n"
"    [\"é\"]\n"
"\n"
"    iex> String.codepoints(\"é\")\n"
"    [\"e\", \"́\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.split(binary)
#: lib/string.ex:241 
msgid ""
"Divides a string into substrings at each Unicode whitespace\n"
"occurrence with leading and trailing whitespace ignored. Groups\n"
"of whitespace are treated as a single occurrence. Divisions do\n"
"not occur on non-breaking whitespace.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.split(\"foo bar\")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\"foo\" <> <<194, 133>> <> \"bar\")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\" foo   bar \")\n"
"    [\"foo\", \"bar\"]\n"
"\n"
"    iex> String.split(\"no\\u00a0break\")\n"
"    [\"no\\u00a0break\"]\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.match?(string, regex)
#: lib/string.ex:1544 
msgid ""
"Checks if `string` matches the given regular expression.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.match?(\"foo\", ~r/foo/)\n"
"    true\n"
"\n"
"    iex> String.match?(\"bar\", ~r/foo/)\n"
"    false\n"
"\n"
msgstr ""
#. TRANSLATORS: def String.to_integer(string)
#: lib/string.ex:1666 
msgid ""
"Returns an integer whose text representation is `string`.\n"
"\n"
"Inlined by the compiler.\n"
"\n"
"## Examples\n"
"\n"
"    iex> String.to_integer(\"123\")\n"
"    123\n"
"\n"
msgstr ""
